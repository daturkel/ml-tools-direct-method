{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09e78acf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "sys.path.append(\"ml-tools-direct-method\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18824c49",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tools.bandit import generate_bandit_feedback\n",
    "from tools.estimate import get_estimator_stats, get_value_estimators\n",
    "from tools.policy import ModelPolicy, UniformPolicy\n",
    "from tools.utils import datasets, get_bandit, split_data\n",
    "\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from numpy.random import default_rng\n",
    "import seaborn as sns\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from tqdm import tqdm\n",
    "\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format='retina'\n",
    "\n",
    "sns.set_palette(\"colorblind\")\n",
    "colors = sns.color_palette()\n",
    "mpl.rcParams[\"axes.labelsize\"] = 12\n",
    "mpl.rcParams[\"axes.titlesize\"] = 14\n",
    "\n",
    "X_MED = 10\n",
    "Y_MED = 6\n",
    "XY_MED = (X_MED, Y_MED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8767ef1c-abfa-46fb-9493-93f5fe99b17f",
   "metadata": {},
   "outputs": [],
   "source": [
    "SKIP_NONLIN = True\n",
    "NUM_TRIALS = 20\n",
    "LOG_CV = False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fb8dcb7",
   "metadata": {},
   "source": [
    "## Experiments with Small Public Datasets "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afaa4c75",
   "metadata": {},
   "outputs": [],
   "source": [
    "frames = {}\n",
    "for data in datasets:\n",
    "\n",
    "    if data in [\n",
    "        \"satimage\",\n",
    "        \"vehicle\",\n",
    "        \"pendigits\",\n",
    "    ]:  # skip these for now, I don't expect them to converge in a linear model.\n",
    "        continue\n",
    "\n",
    "    # configure dataset into bandit setting\n",
    "    print(\"\\n Fetching dataset:\", data)\n",
    "    contexts, full_rewards, best_actions = get_bandit(data)\n",
    "    n, k = full_rewards.shape\n",
    "    _, d = contexts.shape\n",
    "    print(\n",
    "        f\"This dataset has {k} actions, the context space has {d} dimensions, and there are {n} examples.\"\n",
    "    )\n",
    "\n",
    "    # split train test sets\n",
    "    rng = default_rng(3)\n",
    "    X_train, y_train, X_test, y_test, full_rewards_test = split_data(\n",
    "        contexts, full_rewards, best_actions, rng\n",
    "    )\n",
    "\n",
    "    # create target policy using logreg\n",
    "    model = LogisticRegression(multi_class=\"multinomial\", max_iter=10000)\n",
    "    model.fit(X_train, y_train)\n",
    "    target_policy = ModelPolicy(model=model, num_actions=k)\n",
    "\n",
    "    # get true value of target policy -> treated as ground truth for comparing estimates\n",
    "    target_policy_true_value = target_policy.get_value_estimate(\n",
    "        X_test, full_rewards_test\n",
    "    )\n",
    "\n",
    "    # create logging policy\n",
    "    logging_policy = UniformPolicy(num_actions=k)\n",
    "\n",
    "    # run 500 simulations\n",
    "    trials = NUM_TRIALS\n",
    "    val_ests = []\n",
    "    policy = target_policy\n",
    "    policy_true_value = policy.get_value_estimate(X_test, full_rewards_test)\n",
    "    rng = default_rng(6)\n",
    "    for i in tqdm(range(trials)):\n",
    "        contexts, actions, rewards, propensities = generate_bandit_feedback(\n",
    "            X_test, full_rewards_test, logging_policy, rng=rng\n",
    "        )\n",
    "        est = get_value_estimators(\n",
    "            policy,\n",
    "            contexts,\n",
    "            actions,\n",
    "            rewards,\n",
    "            propensities,\n",
    "            skip_nonlin=SKIP_NONLIN,\n",
    "            log_cv=LOG_CV,\n",
    "        )\n",
    "        val_ests.append(est)\n",
    "\n",
    "    df = pd.DataFrame(val_ests)\n",
    "    print(f\"Target policy true value {target_policy_true_value}.\")\n",
    "    df_stats = get_estimator_stats(df, true_parameter_value=policy_true_value)\n",
    "    df_stats[\"true\"] = policy_true_value\n",
    "    print(df_stats)\n",
    "\n",
    "    frames[data] = df_stats\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2744f6c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b1629f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#save estimator dfs for each dataset (so we don't need to re-run)\n",
    "for frame in frames:\n",
    "    frames[frame].to_csv(frame+'.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dabf3e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#only load in datasets used\n",
    "datasets = ['ecoli','glass','letter-recognition','optdigits','yeast']\n",
    "\n",
    "frames = {}\n",
    "for data in datasets:\n",
    "    frames[data] = pd.read_csv(data+'.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09ade12a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualize estimator stats for each dataset\n",
    "\n",
    "stats = [\"mean\", \"bias\", \"var\", \"RMSE\"]\n",
    "skip_nonlin = SKIP_NONLIN\n",
    "for stat in stats:\n",
    "    iw = []\n",
    "    dm = []\n",
    "    dm_iw = []\n",
    "    dm_log = []\n",
    "    dr = []\n",
    "    dm_rf = []\n",
    "    dr_rf = []\n",
    "    for data in datasets:\n",
    "\n",
    "        iw.append(abs(frames[data][stat][0]))\n",
    "        dm.append(abs(frames[data][stat][1]))\n",
    "        dm_iw.append(abs(frames[data][stat][2]))\n",
    "        dm_log.append(abs(frames[data][stat][3]))\n",
    "        dr.append(abs(frames[data][stat][4]))\n",
    "\n",
    "        if not skip_nonlin:\n",
    "            dm_rf.append(abs(frames[data][stat][5]))\n",
    "            dr_rf.append(abs(frames[data][stat][6]))\n",
    "\n",
    "    if skip_nonlin:\n",
    "        df = pd.DataFrame(\n",
    "            np.c_[iw, dm, dm_iw, dm_log, dr],\n",
    "            index=datasets,\n",
    "            columns=[\"iw\", \"dm\", \"dm_iw\", \"dm_log\", \"dr\"],\n",
    "        )\n",
    "        df = (\n",
    "            df.reset_index()\n",
    "            .rename({\"index\": \"dataset\"}, axis=1)\n",
    "            .melt(id_vars=[\"dataset\"], var_name=\"estimator\", value_name=\"estimate\")\n",
    "        )\n",
    "    else:\n",
    "        df = pd.DataFrame(\n",
    "            np.c_[iw, dm, dm_iw, dr, dm_rf, dr_rf],\n",
    "            index=datasets,\n",
    "            columns=[\"iw\", \"dm\", \"dm_iw\", \"dm_log\", \"dr\", \"dm_rf\", \"dr_rf\"],\n",
    "        )\n",
    "        df = (\n",
    "            df.reset_index()\n",
    "            .rename({\"index\": \"dataset\"}, axis=1)\n",
    "            .melt(id_vars=[\"dataset\"], var_name=\"estimator\", value_name=\"estimate\")\n",
    "        )\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=XY_MED)\n",
    "    sns.barplot(data=df, x=\"dataset\", y=\"estimate\", hue=\"estimator\", ax=ax)\n",
    "    ax.legend()\n",
    "    ax.set_title(stat)\n",
    "    ax.tick_params(axis=\"x\", labelrotation=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d2bf030",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
